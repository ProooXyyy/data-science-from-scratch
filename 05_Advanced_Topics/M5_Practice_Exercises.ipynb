{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 5: Practice Exercises\n",
    "\n",
    "Welcome to the practice exercises for Module 5. These questions will test your understanding of the core concepts in Natural Language Processing (NLP) and Time Series Analysis.\n",
    "\n",
    "**Instructions:**\n",
    "1.  For each problem, read the description and write the necessary code in the cell below it.\n",
    "2.  Run the cell to see the output and check if your solution is correct.\n",
    "3.  Solutions are provided at the end of the notebook for you to compare against."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: NLP Pre-processing Pipeline\n",
    "\n",
    "**Task:** You are given a raw text sentence. Perform the complete NLP pre-processing pipeline on it:\n",
    "1.  Tokenize the sentence.\n",
    "2.  Convert all tokens to lowercase.\n",
    "3.  Remove all stop words and punctuation.\n",
    "4.  Lemmatize the remaining tokens.\n",
    "\n",
    "Print the final list of clean, lemmatized tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('punkt', quiet=True)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "raw_text = \"The quick brown foxes are skillfully jumping over the lazy dogs.\"\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: Setting a DatetimeIndex in Pandas\n",
    "\n",
    "**Task:** You are given a Pandas DataFrame where the 'Day' column contains dates as strings. Convert this column into a proper `DatetimeIndex` to make it suitable for time series analysis. Print the `df.info()` to verify that the index has been changed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Day': ['2023-10-01', '2023-10-02', '2023-10-03'],\n",
    "    'Visitors': [150, 165, 158]\n",
    "}\n",
    "df_visitors = pd.DataFrame(data)\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 1:**\n",
    "```python\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "raw_text = \"The quick brown foxes are skillfully jumping over the lazy dogs.\"\n",
    "\n",
    "# 1. Tokenize and convert to lowercase\n",
    "tokens = word_tokenize(raw_text.lower())\n",
    "\n",
    "# 2. Remove stop words and punctuation\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word.isalpha() and word not in stop_words]\n",
    "\n",
    "# 3. Lemmatize\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "\n",
    "print(lemmatized_tokens)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution 2:**\n",
    "```python\n",
    "import pandas as pd\n",
    "data = {\n",
    "    'Day': ['2023-10-01', '2023-10-02', '2023-10-03'],\n",
    "    'Visitors': [150, 165, 158]\n",
    "}\n",
    "df_visitors = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'Day' column to datetime objects\n",
    "df_visitors['Day'] = pd.to_datetime(df_visitors['Day'])\n",
    "\n",
    "# Set the 'Day' column as the index\n",
    "df_visitors.set_index('Day', inplace=True)\n",
    "\n",
    "df_visitors.info()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}