{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 4.5: Model Evaluation Metrics\n",
    "\n",
    "Training a model is only half the battle. How do we know if our model is any good? How do we compare one model to another? The answer lies in **evaluation metrics**. ðŸŽ¯\n",
    "\n",
    "Choosing the right metric is crucial because it defines what we consider a 'good' prediction. A model optimized for one metric might perform poorly on another, so understanding the context of your problem is key.\n",
    "\n",
    "**Goal of this Notebook:**\n",
    "1.  Recap the evaluation metrics for **Regression** and **Classification**.\n",
    "2.  Introduce a powerful visualization tool for classification: the **ROC Curve** and **AUC**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Recap of Key Metrics\n",
    "\n",
    "### For Regression (Predicting a Number)\n",
    "* **Mean Absolute Error (MAE):** The average absolute difference between actual and predicted values. Easy to interpret.\n",
    "* **Mean Squared Error (MSE):** The average of the squared differences. Punishes large errors heavily.\n",
    "* **Root Mean Squared Error (RMSE):** The square root of MSE. Interpretable because it's in the same units as the target (e.g., dollars).\n",
    "\n",
    "### For Classification (Predicting a Category)\n",
    "* **Accuracy:** The overall percentage of correct predictions. Can be misleading if classes are imbalanced.\n",
    "* **Precision:** Answers the question: \"Of all the times the model predicted 'Positive', how often was it right?\" Important when the cost of a false positive is high.\n",
    "* **Recall:** Answers the question: \"Of all the actual 'Positive' cases, how many did the model correctly identify?\" Important when the cost of a false negative is high (e.g., medical diagnosis).\n",
    "* **Confusion Matrix:** A table that provides the raw numbers behind precision and recall (TP, TN, FP, FN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ROC Curve and AUC\n",
    "\n",
    "The **Receiver Operating Characteristic (ROC) Curve** is one of the most important evaluation tools for binary classification.\n",
    "\n",
    "**What it shows:** The ROC curve plots the **True Positive Rate** (same as Recall) against the **False Positive Rate** at various classification thresholds. In simple terms, it shows how good a model is at distinguishing between the positive and negative classes.\n",
    "\n",
    "* A model with no skill will be a diagonal line (the 'coin toss' line).\n",
    "* A perfect model will go straight up the y-axis and then across the x-axis.\n",
    "* Our goal is to have a curve that is as far to the **top-left** as possible.\n",
    "\n",
    "**Area Under the Curve (AUC):**\n",
    "The AUC is the area under the ROC curve. It provides a single number (from 0 to 1) that summarizes the model's performance across all thresholds.\n",
    "\n",
    "* **AUC = 1:** Perfect model.\n",
    "* **AUC = 0.5:** A model with no skill (random guessing).\n",
    "* **AUC < 0.5:** A model that is worse than random guessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and prepare data (same as before)\n",
    "df = pd.read_csv('../02_Data_Analysis_and_Wrangling/data/Social_Network_Ads.csv')\n",
    "X = df[['Age', 'EstimatedSalary']]\n",
    "y = df['Purchased']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
    "\n",
    "# No scaling needed for Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot the ROC curve, we need the predicted probabilities, not just the final classes\n",
    "y_pred_proba = model.predict_proba(X_test)[:, 1] # Probability of the 'positive' class (1)\n",
    "\n",
    "# Calculate ROC curve points\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "\n",
    "# Calculate AUC score\n",
    "auc_score = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Random Forest (AUC = {auc_score:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='No Skill (AUC = 0.5)') # Dashed diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Module Complete!\n",
    "\n",
    "Congratulations! You have completed the **`04_Machine_Learning_Fundamentals`** module. This is a huge milestone.\n",
    "\n",
    "You have learned:\n",
    "* The core workflow of Scikit-Learn (`fit`, `predict`).\n",
    "* How to train models for both **Regression** (Linear Regression) and **Classification** (Logistic Regression, Decision Trees, Random Forests).\n",
    "* The critical importance of the train-test split and feature scaling.\n",
    "* How to evaluate your models using appropriate metrics for both task types.\n",
    "\n",
    "You now have the foundational skills to tackle a wide range of machine learning problems.\n",
    "\n",
    "In the next module, **`05_Advanced_Topics`**, we will explore more specialized and powerful areas like Natural Language Processing (NLP) and Time Series analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}